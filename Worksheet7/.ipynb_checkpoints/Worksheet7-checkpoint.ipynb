{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Regression Task (California Housing)"
      ],
      "metadata": {
        "id": "JZwNSNfPfBl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"camnugent/california-housing-prices\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QusWj6DHfROO",
        "outputId": "9163f4f8-5bba-4f7a-c330-12d97c26d9bf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'california-housing-prices' dataset.\n",
            "Path to dataset files: /kaggle/input/california-housing-prices\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Load and Split Dataset"
      ],
      "metadata": {
        "id": "SorxZh7lfIBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset from Kaggle\n",
        "df = pd.read_csv('/kaggle/input/california-housing-prices/housing.csv')\n",
        "\n",
        "print(f\"Dataset loaded: {df.shape[0]} samples, {df.shape[1]} features\")\n",
        "\n",
        "# Handle missing values\n",
        "df['total_bedrooms'] = df['total_bedrooms'].fillna(df['total_bedrooms'].median())\n",
        "\n",
        "# Prepare features and target\n",
        "X = df.drop('median_house_value', axis=1)\n",
        "y = df['median_house_value']\n",
        "\n",
        "# Convert categorical feature\n",
        "X = pd.get_dummies(X, columns=['ocean_proximity'], drop_first=True)\n",
        "\n",
        "# Convert to numpy\n",
        "X = X.values\n",
        "y = y.values\n",
        "\n",
        "# Split into training (80%) and test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "print(f\"Features: {X_train.shape[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7PfVzTRjACt",
        "outputId": "a961349e-717e-4357-cb12-b8c7e7a7b6c0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded: 20640 samples, 10 features\n",
            "\n",
            "Training set: (16512, 12)\n",
            "Test set: (4128, 12)\n",
            "Features: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2, Step 1: Baseline Model (No Regularization)"
      ],
      "metadata": {
        "id": "yp0sPlVujrXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Build Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Observe coefficients\n",
        "print(\"Coefficients:\")\n",
        "for i in range(min(5, len(model.coef_))):  # Show first 5\n",
        "    print(f\"  Feature {i}: {model.coef_[i]:.6f}\")\n",
        "print(f\"  ... and {len(model.coef_) - 5} more\")\n",
        "print(f\"Intercept: {model.intercept_:.6f}\")\n",
        "\n",
        "# Compute MSE\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"\\nTraining MSE: {mse_train:.6f}\")\n",
        "print(f\"Test MSE: {mse_test:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxQgUyPGjqw8",
        "outputId": "86f7f864-f2a1-4bdd-a05e-f2b3e8738db2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients:\n",
            "  Feature 0: -26838.273372\n",
            "  Feature 1: -25468.352050\n",
            "  Feature 2: 1102.185084\n",
            "  Feature 3: -6.021506\n",
            "  Feature 4: 102.789395\n",
            "  ... and 7 more\n",
            "Intercept: -2275547.381716\n",
            "\n",
            "Training MSE: 4683203783.504253\n",
            "Test MSE: 4908476721.156583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2, Step 2: Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "Ne8aB8SDjwHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define alphas\n",
        "alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "\n",
        "# Ridge Regression tuning\n",
        "ridge = Ridge()\n",
        "ridge_grid = GridSearchCV(ridge, {'alpha': alphas}, cv=5, scoring='neg_mean_squared_error')\n",
        "ridge_grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Ridge - Best alpha: {ridge_grid.best_params_['alpha']}\")\n",
        "\n",
        "# Lasso Regression tuning\n",
        "lasso = Lasso(max_iter=10000)\n",
        "lasso_grid = GridSearchCV(lasso, {'alpha': alphas}, cv=5, scoring='neg_mean_squared_error')\n",
        "lasso_grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Lasso - Best alpha: {lasso_grid.best_params_['alpha']}\")\n",
        "\n",
        "# Test set evaluation\n",
        "ridge_pred = ridge_grid.predict(X_test)\n",
        "lasso_pred = lasso_grid.predict(X_test)\n",
        "\n",
        "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
        "lasso_mse = mean_squared_error(y_test, lasso_pred)\n",
        "\n",
        "print(f\"\\nTest MSE - Ridge: {ridge_mse:.6f}\")\n",
        "print(f\"Test MSE - Lasso: {lasso_mse:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVSa1etnjy10",
        "outputId": "0e87bae6-709e-4142-95ac-f13a981df3f6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge - Best alpha: 1\n",
            "Lasso - Best alpha: 0.001\n",
            "\n",
            "Test MSE - Ridge: 4910037869.229350\n",
            "Test MSE - Lasso: 4908476915.683493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2, Step 3: Regularization Experiments (L1 vs L2)"
      ],
      "metadata": {
        "id": "xLujMeRoj04a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train models with best parameters\n",
        "ridge_best = Ridge(alpha=ridge_grid.best_params_['alpha'])\n",
        "lasso_best = Lasso(alpha=lasso_grid.best_params_['alpha'], max_iter=10000)\n",
        "\n",
        "ridge_best.fit(X_train, y_train)\n",
        "lasso_best.fit(X_train, y_train)\n",
        "\n",
        "# Compare coefficients\n",
        "print(\"\\nCoefficient Comparison (first 10 features):\")\n",
        "print(\"Feature\\tBaseline\\t\\tRidge\\t\\t\\tLasso\")\n",
        "for i in range(10):\n",
        "    print(f\"{i}\\t{model.coef_[i]:.6f}\\t{ridge_best.coef_[i]:.6f}\\t{lasso_best.coef_[i]:.6f}\")\n",
        "\n",
        "# Count zero coefficients\n",
        "zero_lasso = sum(lasso_best.coef_ == 0)\n",
        "print(f\"\\nZero coefficients in Lasso: {zero_lasso}/{len(lasso_best.coef_)}\")\n",
        "\n",
        "# Performance comparison\n",
        "ridge_train_mse = mean_squared_error(y_train, ridge_best.predict(X_train))\n",
        "ridge_test_mse = mean_squared_error(y_test, ridge_best.predict(X_test))\n",
        "\n",
        "lasso_train_mse = mean_squared_error(y_train, lasso_best.predict(X_train))\n",
        "lasso_test_mse = mean_squared_error(y_test, lasso_best.predict(X_test))\n",
        "\n",
        "print(f\"\\nPerformance Comparison:\")\n",
        "print(f\"{'Model':<10} {'Train MSE':<15} {'Test MSE':<15}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'Baseline':<10} {mse_train:<15.6f} {mse_test:<15.6f}\")\n",
        "print(f\"{'Ridge':<10} {ridge_train_mse:<15.6f} {ridge_test_mse:<15.6f}\")\n",
        "print(f\"{'Lasso':<10} {lasso_train_mse:<15.6f} {lasso_test_mse:<15.6f}\")\n",
        "\n",
        "print(\"\\nDiscussion:\")\n",
        "print(\"1. L1 produces sparse coefficients (feature selection)\")\n",
        "print(\"2. L2 shrinks coefficients without zeroing them\")\n",
        "print(\"3. Regularization reduces variance, prevents overfitting\")\n",
        "print(\"4. Excessive regularization increases bias\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrqTj3KSj4_-",
        "outputId": "2cf64771-0e4a-432a-c0ec-3d2efad61cc1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coefficient Comparison (first 10 features):\n",
            "Feature\tBaseline\t\tRidge\t\t\tLasso\n",
            "0\t-26838.273372\t-26860.198129\t-26838.273386\n",
            "1\t-25468.352050\t-25493.131209\t-25468.353841\n",
            "2\t1102.185084\t1102.629029\t1102.185112\n",
            "3\t-6.021506\t-6.019346\t-6.021506\n",
            "4\t102.789395\t102.927379\t102.789411\n",
            "5\t-38.172906\t-38.177632\t-38.172907\n",
            "6\t48.252753\t48.099003\t48.252736\n",
            "7\t39473.975175\t39470.951501\t39473.974756\n",
            "8\t-39786.656161\t-39759.650387\t-39786.649960\n",
            "9\t136125.072615\t108852.317864\t136120.938950\n",
            "\n",
            "Zero coefficients in Lasso: 0/12\n",
            "\n",
            "Performance Comparison:\n",
            "Model      Train MSE       Test MSE       \n",
            "----------------------------------------\n",
            "Baseline   4683203783.504253 4908476721.156583\n",
            "Ridge      4683383574.687478 4910037869.229350\n",
            "Lasso      4683203783.508414 4908476915.683493\n",
            "\n",
            "Discussion:\n",
            "1. L1 produces sparse coefficients (feature selection)\n",
            "2. L2 shrinks coefficients without zeroing them\n",
            "3. Regularization reduces variance, prevents overfitting\n",
            "4. Excessive regularization increases bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 2: CLASSIFICATION TASK (Breast Cancer)"
      ],
      "metadata": {
        "id": "ODEKM8Hlg1gD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Load and Split Dataset"
      ],
      "metadata": {
        "id": "489tsMl-g6f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gg_Knhug8EB",
        "outputId": "984d14d7-d975-472a-b3bb-d03c290d2022"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (455, 30)\n",
            "Test set size: (114, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2, Step 1: Baseline Model (No Regularization)"
      ],
      "metadata": {
        "id": "dLPkYOM3hFHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Build Logistic Regression model\n",
        "logreg_baseline = LogisticRegression(penalty=None, max_iter=10000, solver='lbfgs')\n",
        "logreg_baseline.fit(X_train, y_train)\n",
        "\n",
        "# Observe coefficients\n",
        "print(\"Number of coefficients:\", len(logreg_baseline.coef_[0]))\n",
        "\n",
        "# Compute accuracy\n",
        "y_train_pred = logreg_baseline.predict(X_train)\n",
        "y_test_pred = logreg_baseline.predict(X_test)\n",
        "\n",
        "train_acc = accuracy_score(y_train, y_train_pred)\n",
        "test_acc = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"\\nTraining Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(\"Step 1 completed ✓\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnSani6AhGi2",
        "outputId": "7f1fdec5-c019-4064-cde4-20b9d4cb8f5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of coefficients: 30\n",
            "\n",
            "Training Accuracy: 0.9868\n",
            "Test Accuracy: 0.9825\n",
            "Step 1 completed ✓\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2, Step 2: Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4NO62Qf3hMBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "# Grid Search\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best CV accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "test_acc_tuned = accuracy_score(y_test, best_model.predict(X_test))\n",
        "print(f\"Test Accuracy with best model: {test_acc_tuned:.4f}\")\n",
        "print(\"Step 2 completed ✓\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYUISMvwhH5K",
        "outputId": "dc645af8-3f1b-4606-8a76-9ac0b2c0c2d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best CV accuracy: 0.9670329670329672\n",
            "Test Accuracy with best model: 0.9825\n",
            "Step 2 completed ✓\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2, Step 3: Regularization Experiments (L1 vs L2)"
      ],
      "metadata": {
        "id": "WQbFFdwwiEnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get best parameters for L1 and L2\n",
        "cv_results = grid_search.cv_results_\n",
        "best_l1_idx = None\n",
        "best_l2_idx = None\n",
        "\n",
        "for i, params in enumerate(cv_results['params']):\n",
        "    if params['penalty'] == 'l1':\n",
        "        if best_l1_idx is None or cv_results['mean_test_score'][i] > cv_results['mean_test_score'][best_l1_idx]:\n",
        "            best_l1_idx = i\n",
        "    elif params['penalty'] == 'l2':\n",
        "        if best_l2_idx is None or cv_results['mean_test_score'][i] > cv_results['mean_test_score'][best_l2_idx]:\n",
        "            best_l2_idx = i\n",
        "\n",
        "best_l1_params = cv_results['params'][best_l1_idx]\n",
        "best_l2_params = cv_results['params'][best_l2_idx]\n",
        "\n",
        "print(\"Best L1 parameters:\", best_l1_params)\n",
        "print(\"Best L2 parameters:\", best_l2_params)\n",
        "\n",
        "# Train models with best parameters\n",
        "logreg_l1 = LogisticRegression(**best_l1_params, max_iter=10000)\n",
        "logreg_l2 = LogisticRegression(**best_l2_params, max_iter=10000)\n",
        "\n",
        "logreg_l1.fit(X_train, y_train)\n",
        "logreg_l2.fit(X_train, y_train)\n",
        "\n",
        "# Compare coefficients\n",
        "print(\"\\nCoefficient Comparison (first 10 features):\")\n",
        "print(\"Feature\\t\\tBaseline\\t\\tL1\\t\\t\\tL2\")\n",
        "for i in range(10):\n",
        "    print(f\"{i}\\t\\t{logreg_baseline.coef_[0][i]:.6f}\\t\\t{logreg_l1.coef_[0][i]:.6f}\\t\\t{logreg_l2.coef_[0][i]:.6f}\")\n",
        "\n",
        "# Count zero coefficients\n",
        "zero_l1 = sum(logreg_l1.coef_[0] == 0)\n",
        "print(f\"\\nZero coefficients in L1: {zero_l1}/{len(logreg_l1.coef_[0])}\")\n",
        "\n",
        "# Evaluate and compare accuracy\n",
        "acc_l1_train = accuracy_score(y_train, logreg_l1.predict(X_train))\n",
        "acc_l1_test = accuracy_score(y_test, logreg_l1.predict(X_test))\n",
        "\n",
        "acc_l2_train = accuracy_score(y_train, logreg_l2.predict(X_train))\n",
        "acc_l2_test = accuracy_score(y_test, logreg_l2.predict(X_test))\n",
        "\n",
        "print(f\"\\nAccuracy Comparison:\")\n",
        "print(f\"{'Model':<15} {'Train Acc':<15} {'Test Acc':<15}\")\n",
        "print(\"-\" * 45)\n",
        "print(f\"{'Baseline':<15} {train_acc:<15.4f} {test_acc:<15.4f}\")\n",
        "print(f\"{'L1':<15} {acc_l1_train:<15.4f} {acc_l1_test:<15.4f}\")\n",
        "print(f\"{'L2':<15} {acc_l2_train:<15.4f} {acc_l2_test:<15.4f}\")\n",
        "\n",
        "print(\"\\nDiscussion:\")\n",
        "print(\"1. L1 produces sparse coefficients (feature selection)\")\n",
        "print(\"2. L2 shrinks all coefficients but rarely zero\")\n",
        "print(\"3. Regularization reduces variance and mitigates overfitting\")\n",
        "print(\"4. Overly strong regularization may increase bias\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUBEvGZQhRuM",
        "outputId": "b8aa43ca-8219-4e85-b759-90c9d4c1f8e1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best L1 parameters: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best L2 parameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "\n",
            "Coefficient Comparison (first 10 features):\n",
            "Feature\t\tBaseline\t\tL1\t\t\tL2\n",
            "0\t\t-1.249059\t\t0.753783\t\t4.488356\n",
            "1\t\t-0.019386\t\t-0.108887\t\t0.271960\n",
            "2\t\t0.199959\t\t0.096381\t\t-0.519464\n",
            "3\t\t0.004815\t\t-0.002252\t\t-0.007443\n",
            "4\t\t-17.215768\t\t0.000000\t\t-0.721446\n",
            "5\t\t13.319275\t\t47.268661\t\t-0.695211\n",
            "6\t\t-22.134905\t\t-12.167407\t\t-1.741763\n",
            "7\t\t-39.793068\t\t-136.120490\t\t-1.643938\n",
            "8\t\t8.984611\t\t19.742938\t\t-0.891149\n",
            "9\t\t2.937568\t\t0.000000\t\t0.036918\n",
            "\n",
            "Zero coefficients in L1: 8/30\n",
            "\n",
            "Accuracy Comparison:\n",
            "Model           Train Acc       Test Acc       \n",
            "---------------------------------------------\n",
            "Baseline        0.9868          0.9825         \n",
            "L1              0.9890          0.9825         \n",
            "L2              0.9692          0.9561         \n",
            "\n",
            "Discussion:\n",
            "1. L1 produces sparse coefficients (feature selection)\n",
            "2. L2 shrinks all coefficients but rarely zero\n",
            "3. Regularization reduces variance and mitigates overfitting\n",
            "4. Overly strong regularization may increase bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJwlcHhEiHVi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}